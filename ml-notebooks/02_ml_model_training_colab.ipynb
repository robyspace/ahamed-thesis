{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Serverless-Container Thesis - ML Model Training\n",
    "## Intelligent Router: Lambda vs ECS Platform Selection\n",
    "\n",
    "**Objective:** Train ML models to predict the optimal platform (Lambda or ECS) for different workload types based on cost and latency metrics.\n",
    "\n",
    "**Models:**\n",
    "1. Random Forest (Baseline - Interpretable)\n",
    "2. XGBoost (Target: 85%+ accuracy)\n",
    "3. Neural Network (Deep Learning comparison)\n",
    "\n",
    "**Author:** Ahamed Thesis Project  \n",
    "**Date:** November 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas numpy scikit-learn xgboost matplotlib seaborn plotly imbalanced-learn --quiet\n",
    "print(\"‚úÖ Packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    ")\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "# Neural Network (Keras/TensorFlow)\n",
    "try:\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "    print(\"‚úÖ TensorFlow/Keras imported successfully\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è  TensorFlow not available. Installing...\")\n",
    "    !pip install tensorflow --quiet\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÅ Upload Data Files\n",
    "\n",
    "**Instructions:**\n",
    "1. Run the preprocessing script locally: `python ml-notebooks/01_data_preprocessing.py`\n",
    "2. Upload the generated file: `ml-notebooks/processed-data/ml_training_data.csv`\n",
    "3. Execute the cell below to load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "print(\"üì§ Please upload ml_training_data.csv\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Get the uploaded filename\n",
    "filename = list(uploaded.keys())[0]\n",
    "print(f\"\\n‚úÖ File uploaded: {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DATA OVERVIEW\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTotal samples: {len(df):,}\")\n",
    "print(f\"Features: {len(df.columns)}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SAMPLE DATA\")\n",
    "print(\"=\" * 80)\n",
    "display(df.head())\n",
    "\n",
    "# Data types\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATA TYPES\")\n",
    "print(\"=\" * 80)\n",
    "print(df.dtypes)\n",
    "\n",
    "# Missing values\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MISSING VALUES\")\n",
    "print(\"=\" * 80)\n",
    "missing = df.isnull().sum()\n",
    "if missing.sum() > 0:\n",
    "    print(missing[missing > 0])\n",
    "else:\n",
    "    print(\"‚úÖ No missing values!\")\n",
    "\n",
    "# Label distribution\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"LABEL DISTRIBUTION\")\n",
    "print(\"=\" * 80)\n",
    "label_counts = df['optimal_platform'].value_counts()\n",
    "print(f\"Lambda (1): {label_counts.get(1, 0):,} ({label_counts.get(1, 0) / len(df) * 100:.1f}%)\")\n",
    "print(f\"ECS (0): {label_counts.get(0, 0):,} ({label_counts.get(0, 0) / len(df) * 100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workload type distribution\n",
    "fig = px.histogram(\n",
    "    df, \n",
    "    x='workload_type', \n",
    "    color='optimal_platform',\n",
    "    title='Workload Distribution by Optimal Platform',\n",
    "    labels={'optimal_platform': 'Optimal Platform (1=Lambda, 0=ECS)'},\n",
    "    barmode='group'\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Cost comparison\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('Lambda Cost Distribution', 'ECS Cost Distribution')\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=df['lambda_cost_usd'], name='Lambda Cost', nbinsx=50),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=df['ecs_cost_usd'], name='ECS Cost', nbinsx=50),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(title_text=\"Cost Distribution by Platform\", showlegend=False)\n",
    "fig.show()\n",
    "\n",
    "# Latency comparison\n",
    "fig = px.box(\n",
    "    df, \n",
    "    x='workload_type', \n",
    "    y='lambda_latency_ms',\n",
    "    color='optimal_platform',\n",
    "    title='Lambda Latency by Workload Type and Optimal Platform',\n",
    "    labels={'lambda_latency_ms': 'Latency (ms)'}\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Feature Selection and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features for ML models\n",
    "# These are the features that will be available at runtime for prediction\n",
    "FEATURE_COLUMNS = [\n",
    "    'workload_type_encoded',  # Type of workload\n",
    "    'payload_size_kb',        # Size of payload\n",
    "    'hour_of_day',            # Time of day\n",
    "    'day_of_week',            # Day of week\n",
    "    'is_weekend',             # Weekend flag\n",
    "]\n",
    "\n",
    "TARGET_COLUMN = 'optimal_platform'  # 1 = Lambda, 0 = ECS\n",
    "\n",
    "# Extract features and target\n",
    "X = df[FEATURE_COLUMNS].copy()\n",
    "y = df[TARGET_COLUMN].copy()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FEATURE SELECTION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nFeatures selected: {len(FEATURE_COLUMNS)}\")\n",
    "for i, col in enumerate(FEATURE_COLUMNS, 1):\n",
    "    print(f\"  {i}. {col}\")\n",
    "\n",
    "print(f\"\\nTarget variable: {TARGET_COLUMN}\")\n",
    "print(f\"Samples: {len(X):,}\")\n",
    "\n",
    "# Check for any missing values in selected features\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FEATURE QUALITY CHECK\")\n",
    "print(\"=\" * 80)\n",
    "missing_features = X.isnull().sum()\n",
    "if missing_features.sum() > 0:\n",
    "    print(\"‚ö†Ô∏è  Missing values detected:\")\n",
    "    print(missing_features[missing_features > 0])\n",
    "    print(\"\\nFilling missing values with median...\")\n",
    "    X = X.fillna(X.median())\n",
    "else:\n",
    "    print(\"‚úÖ No missing values in selected features\")\n",
    "\n",
    "# Display feature statistics\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FEATURE STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "display(X.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÄ Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train (70%), validation (15%), and test (15%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TRAIN-VALIDATION-TEST SPLIT\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTotal samples: {len(X):,}\")\n",
    "print(f\"\\nTraining set: {len(X_train):,} ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"Validation set: {len(X_val):,} ({len(X_val)/len(X)*100:.1f}%)\")\n",
    "print(f\"Test set: {len(X_test):,} ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"LABEL DISTRIBUTION IN SPLITS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nTraining set:\")\n",
    "print(f\"  Lambda (1): {(y_train == 1).sum():,} ({(y_train == 1).mean()*100:.1f}%)\")\n",
    "print(f\"  ECS (0): {(y_train == 0).sum():,} ({(y_train == 0).mean()*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nValidation set:\")\n",
    "print(f\"  Lambda (1): {(y_val == 1).sum():,} ({(y_val == 1).mean()*100:.1f}%)\")\n",
    "print(f\"  ECS (0): {(y_val == 0).sum():,} ({(y_val == 0).mean()*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nTest set:\")\n",
    "print(f\"  Lambda (1): {(y_test == 1).sum():,} ({(y_test == 1).mean()*100:.1f}%)\")\n",
    "print(f\"  ECS (0): {(y_test == 0).sum():,} ({(y_test == 0).mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìè Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features for Neural Network (Random Forest and XGBoost don't require scaling)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"‚úÖ Features scaled using StandardScaler\")\n",
    "print(f\"   Mean: {scaler.mean_}\")\n",
    "print(f\"   Std: {scaler.scale_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üå≤ Model 1: Random Forest Classifier\n",
    "\n",
    "**Baseline model** - Interpretable and robust to feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"TRAINING RANDOM FOREST CLASSIFIER\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Train Random Forest\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n‚úÖ Random Forest training complete!\")\n",
    "\n",
    "# Predictions\n",
    "y_train_pred_rf = rf_model.predict(X_train)\n",
    "y_val_pred_rf = rf_model.predict(X_val)\n",
    "y_test_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RANDOM FOREST PERFORMANCE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nüìä Training Set:\")\n",
    "print(f\"  Accuracy: {accuracy_score(y_train, y_train_pred_rf):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_train, y_train_pred_rf):.4f}\")\n",
    "print(f\"  Recall: {recall_score(y_train, y_train_pred_rf):.4f}\")\n",
    "print(f\"  F1-Score: {f1_score(y_train, y_train_pred_rf):.4f}\")\n",
    "\n",
    "print(\"\\nüìä Validation Set:\")\n",
    "print(f\"  Accuracy: {accuracy_score(y_val, y_val_pred_rf):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_val, y_val_pred_rf):.4f}\")\n",
    "print(f\"  Recall: {recall_score(y_val, y_val_pred_rf):.4f}\")\n",
    "print(f\"  F1-Score: {f1_score(y_val, y_val_pred_rf):.4f}\")\n",
    "\n",
    "print(\"\\nüìä Test Set:\")\n",
    "print(f\"  Accuracy: {accuracy_score(y_test, y_test_pred_rf):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_test, y_test_pred_rf):.4f}\")\n",
    "print(f\"  Recall: {recall_score(y_test, y_test_pred_rf):.4f}\")\n",
    "print(f\"  F1-Score: {f1_score(y_test, y_test_pred_rf):.4f}\")\n",
    "\n",
    "# Feature importance\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FEATURE IMPORTANCE\")\n",
    "print(\"=\" * 80)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': FEATURE_COLUMNS,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(feature_importance.to_string(index=False))\n",
    "\n",
    "# Visualize feature importance\n",
    "fig = px.bar(\n",
    "    feature_importance,\n",
    "    x='importance',\n",
    "    y='feature',\n",
    "    orientation='h',\n",
    "    title='Random Forest Feature Importance'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Model 2: XGBoost Classifier\n",
    "\n",
    "**Target: 85%+ accuracy** - Gradient boosting for high performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"TRAINING XGBOOST CLASSIFIER\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Train XGBoost\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "xgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "    verbose=50\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ XGBoost training complete!\")\n",
    "\n",
    "# Predictions\n",
    "y_train_pred_xgb = xgb_model.predict(X_train)\n",
    "y_val_pred_xgb = xgb_model.predict(X_val)\n",
    "y_test_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"XGBOOST PERFORMANCE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nüìä Training Set:\")\n",
    "print(f\"  Accuracy: {accuracy_score(y_train, y_train_pred_xgb):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_train, y_train_pred_xgb):.4f}\")\n",
    "print(f\"  Recall: {recall_score(y_train, y_train_pred_xgb):.4f}\")\n",
    "print(f\"  F1-Score: {f1_score(y_train, y_train_pred_xgb):.4f}\")\n",
    "\n",
    "print(\"\\nüìä Validation Set:\")\n",
    "print(f\"  Accuracy: {accuracy_score(y_val, y_val_pred_xgb):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_val, y_val_pred_xgb):.4f}\")\n",
    "print(f\"  Recall: {recall_score(y_val, y_val_pred_xgb):.4f}\")\n",
    "print(f\"  F1-Score: {f1_score(y_val, y_val_pred_xgb):.4f}\")\n",
    "\n",
    "print(\"\\nüìä Test Set:\")\n",
    "print(f\"  Accuracy: {accuracy_score(y_test, y_test_pred_xgb):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_test, y_test_pred_xgb):.4f}\")\n",
    "print(f\"  Recall: {recall_score(y_test, y_test_pred_xgb):.4f}\")\n",
    "print(f\"  F1-Score: {f1_score(y_test, y_test_pred_xgb):.4f}\")\n",
    "\n",
    "# Feature importance\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FEATURE IMPORTANCE\")\n",
    "print(\"=\" * 80)\n",
    "xgb_feature_importance = pd.DataFrame({\n",
    "    'feature': FEATURE_COLUMNS,\n",
    "    'importance': xgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(xgb_feature_importance.to_string(index=False))\n",
    "\n",
    "# Visualize feature importance\n",
    "fig = px.bar(\n",
    "    xgb_feature_importance,\n",
    "    x='importance',\n",
    "    y='feature',\n",
    "    orientation='h',\n",
    "    title='XGBoost Feature Importance'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† Model 3: Neural Network (Deep Learning)\n",
    "\n",
    "**Comparison model** - Deep learning approach with TensorFlow/Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"BUILDING NEURAL NETWORK\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Build Neural Network architecture\n",
    "nn_model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(len(FEATURE_COLUMNS),)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(32, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "nn_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', 'precision', 'recall']\n",
    ")\n",
    "\n",
    "print(nn_model.summary())\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=0.00001,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRAINING NEURAL NETWORK\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Train model\n",
    "history = nn_model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_data=(X_val_scaled, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Neural Network training complete!\")\n",
    "\n",
    "# Predictions\n",
    "y_train_pred_nn_prob = nn_model.predict(X_train_scaled)\n",
    "y_val_pred_nn_prob = nn_model.predict(X_val_scaled)\n",
    "y_test_pred_nn_prob = nn_model.predict(X_test_scaled)\n",
    "\n",
    "y_train_pred_nn = (y_train_pred_nn_prob > 0.5).astype(int).flatten()\n",
    "y_val_pred_nn = (y_val_pred_nn_prob > 0.5).astype(int).flatten()\n",
    "y_test_pred_nn = (y_test_pred_nn_prob > 0.5).astype(int).flatten()\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"NEURAL NETWORK PERFORMANCE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nüìä Training Set:\")\n",
    "print(f\"  Accuracy: {accuracy_score(y_train, y_train_pred_nn):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_train, y_train_pred_nn):.4f}\")\n",
    "print(f\"  Recall: {recall_score(y_train, y_train_pred_nn):.4f}\")\n",
    "print(f\"  F1-Score: {f1_score(y_train, y_train_pred_nn):.4f}\")\n",
    "\n",
    "print(\"\\nüìä Validation Set:\")\n",
    "print(f\"  Accuracy: {accuracy_score(y_val, y_val_pred_nn):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_val, y_val_pred_nn):.4f}\")\n",
    "print(f\"  Recall: {recall_score(y_val, y_val_pred_nn):.4f}\")\n",
    "print(f\"  F1-Score: {f1_score(y_val, y_val_pred_nn):.4f}\")\n",
    "\n",
    "print(\"\\nüìä Test Set:\")\n",
    "print(f\"  Accuracy: {accuracy_score(y_test, y_test_pred_nn):.4f}\")\n",
    "print(f\"  Precision: {precision_score(y_test, y_test_pred_nn):.4f}\")\n",
    "print(f\"  Recall: {recall_score(y_test, y_test_pred_nn):.4f}\")\n",
    "print(f\"  F1-Score: {f1_score(y_test, y_test_pred_nn):.4f}\")\n",
    "\n",
    "# Plot training history\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('Model Accuracy', 'Model Loss')\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=history.history['accuracy'], name='Train Accuracy', mode='lines'),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=history.history['val_accuracy'], name='Val Accuracy', mode='lines'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=history.history['loss'], name='Train Loss', mode='lines'),\n",
    "    row=1, col=2\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=history.history['val_loss'], name='Val Loss', mode='lines'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"Epoch\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Epoch\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Accuracy\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Loss\", row=1, col=2)\n",
    "\n",
    "fig.update_layout(title_text=\"Neural Network Training History\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Model Comparison and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile results\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'XGBoost', 'Neural Network'],\n",
    "    'Train_Accuracy': [\n",
    "        accuracy_score(y_train, y_train_pred_rf),\n",
    "        accuracy_score(y_train, y_train_pred_xgb),\n",
    "        accuracy_score(y_train, y_train_pred_nn)\n",
    "    ],\n",
    "    'Val_Accuracy': [\n",
    "        accuracy_score(y_val, y_val_pred_rf),\n",
    "        accuracy_score(y_val, y_val_pred_xgb),\n",
    "        accuracy_score(y_val, y_val_pred_nn)\n",
    "    ],\n",
    "    'Test_Accuracy': [\n",
    "        accuracy_score(y_test, y_test_pred_rf),\n",
    "        accuracy_score(y_test, y_test_pred_xgb),\n",
    "        accuracy_score(y_test, y_test_pred_nn)\n",
    "    ],\n",
    "    'Test_Precision': [\n",
    "        precision_score(y_test, y_test_pred_rf),\n",
    "        precision_score(y_test, y_test_pred_xgb),\n",
    "        precision_score(y_test, y_test_pred_nn)\n",
    "    ],\n",
    "    'Test_Recall': [\n",
    "        recall_score(y_test, y_test_pred_rf),\n",
    "        recall_score(y_test, y_test_pred_xgb),\n",
    "        recall_score(y_test, y_test_pred_nn)\n",
    "    ],\n",
    "    'Test_F1': [\n",
    "        f1_score(y_test, y_test_pred_rf),\n",
    "        f1_score(y_test, y_test_pred_xgb),\n",
    "        f1_score(y_test, y_test_pred_nn)\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "display(results)\n",
    "\n",
    "# Find best model\n",
    "best_model_idx = results['Test_Accuracy'].idxmax()\n",
    "best_model_name = results.loc[best_model_idx, 'Model']\n",
    "best_accuracy = results.loc[best_model_idx, 'Test_Accuracy']\n",
    "\n",
    "print(f\"\\nüèÜ Best Model: {best_model_name} (Test Accuracy: {best_accuracy:.4f})\")\n",
    "\n",
    "if best_accuracy >= 0.85:\n",
    "    print(\"‚úÖ Target accuracy of 85% achieved!\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Target accuracy of 85% not yet achieved. Current: {best_accuracy:.4f}\")\n",
    "\n",
    "# Visualize comparison\n",
    "fig = go.Figure()\n",
    "\n",
    "metrics = ['Train_Accuracy', 'Val_Accuracy', 'Test_Accuracy', 'Test_Precision', 'Test_Recall', 'Test_F1']\n",
    "for model in results['Model']:\n",
    "    model_data = results[results['Model'] == model]\n",
    "    fig.add_trace(go.Bar(\n",
    "        name=model,\n",
    "        x=metrics,\n",
    "        y=model_data[metrics].values[0]\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Model Performance Comparison',\n",
    "    xaxis_title='Metrics',\n",
    "    yaxis_title='Score',\n",
    "    barmode='group'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìâ Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrices for all models\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "models_cm = [\n",
    "    ('Random Forest', y_test_pred_rf),\n",
    "    ('XGBoost', y_test_pred_xgb),\n",
    "    ('Neural Network', y_test_pred_nn)\n",
    "]\n",
    "\n",
    "for idx, (model_name, y_pred) in enumerate(models_cm):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx])\n",
    "    axes[idx].set_title(f'{model_name}\\nConfusion Matrix')\n",
    "    axes[idx].set_xlabel('Predicted')\n",
    "    axes[idx].set_ylabel('Actual')\n",
    "    axes[idx].set_xticklabels(['ECS (0)', 'Lambda (1)'])\n",
    "    axes[idx].set_yticklabels(['ECS (0)', 'Lambda (1)'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print classification reports\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DETAILED CLASSIFICATION REPORTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for model_name, y_pred in models_cm:\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(classification_report(y_test, y_pred, target_names=['ECS (0)', 'Lambda (1)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üíæ Save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the best performing model\n",
    "if best_model_name == 'Random Forest':\n",
    "    best_model = rf_model\n",
    "elif best_model_name == 'XGBoost':\n",
    "    best_model = xgb_model\n",
    "else:\n",
    "    best_model = nn_model\n",
    "\n",
    "# Save model\n",
    "model_filename = f'best_model_{best_model_name.replace(\" \", \"_\").lower()}.pkl'\n",
    "\n",
    "if best_model_name != 'Neural Network':\n",
    "    with open(model_filename, 'wb') as f:\n",
    "        pickle.dump(best_model, f)\n",
    "    print(f\"‚úÖ Model saved: {model_filename}\")\n",
    "else:\n",
    "    nn_model.save('best_model_neural_network.h5')\n",
    "    print(f\"‚úÖ Neural Network saved: best_model_neural_network.h5\")\n",
    "\n",
    "# Save scaler (needed for Neural Network)\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(f\"‚úÖ Scaler saved: scaler.pkl\")\n",
    "\n",
    "# Save feature names\n",
    "with open('feature_columns.json', 'w') as f:\n",
    "    json.dump(FEATURE_COLUMNS, f)\n",
    "print(f\"‚úÖ Feature columns saved: feature_columns.json\")\n",
    "\n",
    "# Save model metadata\n",
    "metadata = {\n",
    "    'best_model': best_model_name,\n",
    "    'test_accuracy': float(best_accuracy),\n",
    "    'feature_columns': FEATURE_COLUMNS,\n",
    "    'training_samples': len(X_train),\n",
    "    'test_samples': len(X_test),\n",
    "    'model_performance': results.to_dict('records')\n",
    "}\n",
    "\n",
    "with open('model_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(f\"‚úÖ Metadata saved: model_metadata.json\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üéâ MODEL TRAINING COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "print(f\"Test Accuracy: {best_accuracy:.4f}\")\n",
    "print(f\"\\nFiles ready for download and AWS deployment:\")\n",
    "print(f\"  1. {model_filename if best_model_name != 'Neural Network' else 'best_model_neural_network.h5'}\")\n",
    "print(f\"  2. scaler.pkl\")\n",
    "print(f\"  3. feature_columns.json\")\n",
    "print(f\"  4. model_metadata.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üì• Download Model Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Download all model files\n",
    "print(\"üì• Downloading model files...\")\n",
    "\n",
    "if best_model_name != 'Neural Network':\n",
    "    files.download(model_filename)\n",
    "else:\n",
    "    files.download('best_model_neural_network.h5')\n",
    "\n",
    "files.download('scaler.pkl')\n",
    "files.download('feature_columns.json')\n",
    "files.download('model_metadata.json')\n",
    "\n",
    "print(\"\\n‚úÖ All files downloaded successfully!\")\n",
    "print(\"\\nüöÄ Next Steps:\")\n",
    "print(\"  1. Upload model files to your repository\")\n",
    "print(\"  2. Create intelligent router API on AWS Lambda\")\n",
    "print(\"  3. Deploy and test the hybrid routing system\")\n",
    "print(\"  4. Evaluate against Lambda-only and ECS-only baselines\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
